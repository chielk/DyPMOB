% vim: set spell:
\author{Chiel Kooijman - 5743028}
\title{Logbook Bachelor Project}
\documentclass{article}
\usepackage{graphicx,amsmath}
\begin{document}
	\maketitle

	\section{Background}
	\label{sec:background}
	Ideas that came up during the first meeting with supervisor Diederik
	Roijers, and by thinking on the proposed problem some more.

	\paragraph{Problem Description}
	\label{par:problem_description}
	Most RL algorithms work well on finite state and action spaces, but most
	real-world problems are continuous. One approach is discretisation, but a
	problem is that a human user may not always know the optimal way to do this.
	The aim of this research is to provide an efficient way of dynamically
	optimising the state-space on-line.
	Possible solutions should preferably be able to cope well with uncertainty
	about the current state. The state may be represented as a $\mu$ and
	$\sigma$, like the output of a kalman filter, which is commonly used for
	representing uncertainty in robots.
	The main idea that underlies this approach is that the world is virtually
	fully deterministic, so when it seems that it is stochastic, this is a
	result of insufficient information or an inability to extract the
	discriminating features from the information that is available.
	% paragraph problem_description (end)

	\paragraph{Initial Idea}
	\label{par:initial_idea}
	As established with Diederik.
	Start state space at a low resolution (i.e. large squares).
	Split the states dynamically as uncertainty (about reward or next state?)
	increases. Increase the resolution of areas with high uncertainty over time.
	\\
	Expected advantages: The low resolution initially will make generalisation
	easier, which will make the RL learn faster/with fewer training examples
	than starting off at a high resolution and may find more optimal policies
	than with a static low resolution. May be able to handle uncertainty about
	the current state (POMDP) in an elegant/efficient way, both in terms of
	reward and complexity.
	\\
	Expected limitations: It may not cope very well if the world is stochastic
	if it is unable to discriminate between uncertainty about it's observations
	(internal) and uncertainty inherent to the world (external)
	% paragraph initial_idea (end)Initial approach}

	\paragraph{Possible Alternative}
	\label{par:possible_alternative}
	Approach states similarly to a nearest neighbour problem by adding them as
	they are visited. Combine similar states over time to reduce complexity and
	increase generalisation, and only add new states if they seem to indicate a
	limit to the accuracy of states that have up to that point matched the
	observations best.
	By using a Gaussian blur/probability distribution, it will be able to give
	predictions about states that would not have fit into any known state with
	discretisation. If the probability of being in any known state is very low,
	and the reward is different than predicted by this state, it could be seen
	as an indication that this was indeed a different state and a new one may be
	added.
	\\
	Expected Advantages: Higher precision than discretisation. Prediction about
	unvisited states. The $\mu$ and $\sigma$ of the estimated location of the
	agent may be directly used for the state description. Mathematics of
	combining Gaussian distributions is well understood and may provide a more
	accurate representation of uncertainty than discrete models.
	\\
	Expected disadvantages: Possibly has more parameters than discretisation
	idea. More difficult to design and test. Hard to tell what would/should
	happen in a stochastic world.
	% paragraph possible_alternative (end)
	% section background (end)

	\section{18 April}
	\label{sec:18_april}
	Wrote section \ref{sec:background}
	Read article van Hasselt.
	% section 18_april (end)
\end{document}
